{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-10T12:06:54.833885Z","iopub.execute_input":"2024-10-10T12:06:54.834310Z","iopub.status.idle":"2024-10-10T12:06:56.018294Z","shell.execute_reply.started":"2024-10-10T12:06:54.834267Z","shell.execute_reply":"2024-10-10T12:06:56.017143Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Subset, DataLoader\n\n# Define transformation for MNIST (e.g., convert to tensor)\ntransform = transforms.Compose([transforms.ToTensor()\n                               ,transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\n# Load the full MNIST training dataset\nmnist_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\nmnist_test = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n\n\n# Create a DataLoader for the subset\ntest_loader = DataLoader(mnist_test, batch_size=64, shuffle=True)\n\n\n# Select the first 600 images for training\nsubset_indices_1 = list(range(640))\nmnist_subset_1 = Subset(mnist_train, subset_indices_1)\n\n# Create a DataLoader for the subset\ntrain_loader_1 = DataLoader(mnist_subset_1, batch_size=64, shuffle=True)\n\n# Select the first 600 images for training\nsubset_indices_2 = list(range(640,1280))\nmnist_subset_2 = Subset(mnist_train, subset_indices_2)\n\n# Create a DataLoader for the subset\ntrain_loader_2 = DataLoader(mnist_subset_2, batch_size=64, shuffle=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T12:06:57.762452Z","iopub.execute_input":"2024-10-10T12:06:57.763070Z","iopub.status.idle":"2024-10-10T12:07:10.864249Z","shell.execute_reply.started":"2024-10-10T12:06:57.763014Z","shell.execute_reply":"2024-10-10T12:07:10.863181Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:04<00:00, 42482153.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\n\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)  # 3 input channels (for CIFAR-10), 10 output channels\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)  # 10 input channels, 20 output channels\n        self.fc1 = nn.Linear(500, 50)  # We'll compute 500 dynamically based on input size\n        self.fc2 = nn.Linear(50, 10)  # 10 output features (CIFAR-10 has 10 classes)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))  # RELU activation, max pooling\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))  # RELU activation, max pooling\n        x = x.view(x.size(0), -1)  # Dynamically flatten the output\n        x = F.relu(self.fc1(x))  # RELU activation\n        x = self.fc2(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T12:18:31.593443Z","iopub.execute_input":"2024-10-10T12:18:31.594229Z","iopub.status.idle":"2024-10-10T12:18:31.604646Z","shell.execute_reply.started":"2024-10-10T12:18:31.594183Z","shell.execute_reply":"2024-10-10T12:18:31.603238Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\ndef evaluate(model,loader) -> float:\n    correct, total = 0, 0\n    model.eval()\n    with torch.no_grad():\n        for data in loader:\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    return correct / total\n\ndef train(model,train_loader,batch_size=64,EPOCHS=5):\n    model.to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n    model.train()\n    for epoch in range(EPOCHS):\n        running_loss = 0.0\n        running_correct = 0.0\n        model = model.to(device)\n        for i, data in enumerate(train_loader, 0):\n            output = None\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            running_correct += (labels == predicted).sum().item()\n        epoch_loss = running_loss / len(train_loader)\n        epoch_accuracy = running_correct / (len(train_loader) * 64)\n        test_accuracy = evaluate(model,test_loader)\n        model.train()\n        print(f\"Epoch [{epoch+1}/{EPOCHS}]: Loss: {epoch_loss}, Train accuracy: {epoch_accuracy}, Test accuracy: {test_accuracy}\")\n    return  model","metadata":{"execution":{"iopub.status.busy":"2024-10-10T12:20:15.865198Z","iopub.execute_input":"2024-10-10T12:20:15.865748Z","iopub.status.idle":"2024-10-10T12:20:15.880574Z","shell.execute_reply.started":"2024-10-10T12:20:15.865701Z","shell.execute_reply":"2024-10-10T12:20:15.879324Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T12:20:16.032813Z","iopub.execute_input":"2024-10-10T12:20:16.033256Z","iopub.status.idle":"2024-10-10T12:20:16.039931Z","shell.execute_reply.started":"2024-10-10T12:20:16.033211Z","shell.execute_reply":"2024-10-10T12:20:16.038644Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import torch\nimport copy\n\n# Assume model_list is a list of models\ndef average_model_weights(model_list):\n    avg_model_state_dict = copy.deepcopy(model_list[0])\n    \n    for key in avg_model_state_dict:\n        avg_model_state_dict[key] = torch.zeros_like(avg_model_state_dict[key])\n\n    num_models = len(model_list)\n    for model_state_dict in model_list:\n        for key in avg_model_state_dict:\n            avg_model_state_dict[key] += model_state_dict[key]\n    \n    for key in avg_model_state_dict:\n        avg_model_state_dict[key] /= num_models\n\n    return avg_model_state_dict\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T12:20:16.188928Z","iopub.execute_input":"2024-10-10T12:20:16.189378Z","iopub.status.idle":"2024-10-10T12:20:16.197118Z","shell.execute_reply.started":"2024-10-10T12:20:16.189334Z","shell.execute_reply":"2024-10-10T12:20:16.195807Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_loaders = [train_loader_1, train_loader_2]\n\ndef server_execute(t,E,K):\n    w0 = copy.deepcopy((SimpleCNN()).state_dict())\n    for i in range(t):\n        weights = []\n        for k in range(K):\n            weights.append(ClientUpdate(w0,E,k))\n        w0 = average_model_weights(weights)\n        avg_model = SimpleCNN()\n        avg_model.load_state_dict(w0)\n        print(f\"round {i} accuracy: {evaluate(avg_model,test_loader)}\")\n    \ndef ClientUpdate(w,E,k):\n    model = SimpleCNN()\n    model.load_state_dict(state_dict=w)\n    model = train(model,train_loaders[k],EPOCHS=E)\n    print(f\"k={k}: {evaluate(model,test_loader)}\")\n    return model.state_dict()\n\nserver_execute(5,10,2)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T12:26:43.904561Z","iopub.execute_input":"2024-10-10T12:26:43.905048Z","iopub.status.idle":"2024-10-10T12:35:04.947491Z","shell.execute_reply.started":"2024-10-10T12:26:43.905005Z","shell.execute_reply":"2024-10-10T12:35:04.946244Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch [1/10]: Loss: 2.3039036273956297, Train accuracy: 0.096875, Test accuracy: 0.1056\nEpoch [2/10]: Loss: 2.2890339374542235, Train accuracy: 0.125, Test accuracy: 0.1002\nEpoch [3/10]: Loss: 2.2713544845581053, Train accuracy: 0.1234375, Test accuracy: 0.1\nEpoch [4/10]: Loss: 2.2482853174209594, Train accuracy: 0.1234375, Test accuracy: 0.103\nEpoch [5/10]: Loss: 2.212786626815796, Train accuracy: 0.15, Test accuracy: 0.1593\nEpoch [6/10]: Loss: 2.1436119556427, Train accuracy: 0.24375, Test accuracy: 0.2176\nEpoch [7/10]: Loss: 2.0526759147644045, Train accuracy: 0.2890625, Test accuracy: 0.247\nEpoch [8/10]: Loss: 2.0005127429962157, Train accuracy: 0.2828125, Test accuracy: 0.249\nEpoch [9/10]: Loss: 1.9372020721435548, Train accuracy: 0.290625, Test accuracy: 0.2738\nEpoch [10/10]: Loss: 1.8589028596878052, Train accuracy: 0.365625, Test accuracy: 0.2962\nk=0: 0.2962\nEpoch [1/10]: Loss: 2.3030240535736084, Train accuracy: 0.096875, Test accuracy: 0.1198\nEpoch [2/10]: Loss: 2.292186450958252, Train accuracy: 0.171875, Test accuracy: 0.1818\nEpoch [3/10]: Loss: 2.2807263374328612, Train accuracy: 0.2109375, Test accuracy: 0.1888\nEpoch [4/10]: Loss: 2.2611716985702515, Train accuracy: 0.2421875, Test accuracy: 0.1997\nEpoch [5/10]: Loss: 2.222517156600952, Train accuracy: 0.246875, Test accuracy: 0.2035\nEpoch [6/10]: Loss: 2.1433377265930176, Train accuracy: 0.2515625, Test accuracy: 0.2152\nEpoch [7/10]: Loss: 2.051720178127289, Train accuracy: 0.2671875, Test accuracy: 0.2281\nEpoch [8/10]: Loss: 1.9946802496910094, Train accuracy: 0.2796875, Test accuracy: 0.2357\nEpoch [9/10]: Loss: 1.944589412212372, Train accuracy: 0.275, Test accuracy: 0.2663\nEpoch [10/10]: Loss: 1.8656059861183167, Train accuracy: 0.321875, Test accuracy: 0.2819\nk=1: 0.2819\nround 0 accuracy: 0.2929\nEpoch [1/10]: Loss: 1.8595088362693786, Train accuracy: 0.3296875, Test accuracy: 0.3013\nEpoch [2/10]: Loss: 1.8464502215385437, Train accuracy: 0.325, Test accuracy: 0.2845\nEpoch [3/10]: Loss: 1.7902663350105286, Train accuracy: 0.35, Test accuracy: 0.2935\nEpoch [4/10]: Loss: 1.750279474258423, Train accuracy: 0.371875, Test accuracy: 0.2971\nEpoch [5/10]: Loss: 1.7041906118392944, Train accuracy: 0.384375, Test accuracy: 0.3268\nEpoch [6/10]: Loss: 1.6362735152244567, Train accuracy: 0.4359375, Test accuracy: 0.3286\nEpoch [7/10]: Loss: 1.6069617033004762, Train accuracy: 0.425, Test accuracy: 0.3131\nEpoch [8/10]: Loss: 1.5814197421073914, Train accuracy: 0.4328125, Test accuracy: 0.3378\nEpoch [9/10]: Loss: 1.4997702598571778, Train accuracy: 0.459375, Test accuracy: 0.3375\nEpoch [10/10]: Loss: 1.4352433919906615, Train accuracy: 0.5046875, Test accuracy: 0.3342\nk=0: 0.3342\nEpoch [1/10]: Loss: 1.8828601956367492, Train accuracy: 0.3203125, Test accuracy: 0.2957\nEpoch [2/10]: Loss: 1.8308938026428223, Train accuracy: 0.3328125, Test accuracy: 0.3001\nEpoch [3/10]: Loss: 1.808533215522766, Train accuracy: 0.334375, Test accuracy: 0.3177\nEpoch [4/10]: Loss: 1.7578936457633971, Train accuracy: 0.346875, Test accuracy: 0.3143\nEpoch [5/10]: Loss: 1.7071056604385375, Train accuracy: 0.3984375, Test accuracy: 0.315\nEpoch [6/10]: Loss: 1.6286035656929017, Train accuracy: 0.4171875, Test accuracy: 0.3343\nEpoch [7/10]: Loss: 1.5980520129203797, Train accuracy: 0.4234375, Test accuracy: 0.3275\nEpoch [8/10]: Loss: 1.539277935028076, Train accuracy: 0.4296875, Test accuracy: 0.3352\nEpoch [9/10]: Loss: 1.5296449422836305, Train accuracy: 0.4296875, Test accuracy: 0.3255\nEpoch [10/10]: Loss: 1.515373742580414, Train accuracy: 0.44375, Test accuracy: 0.3329\nk=1: 0.3329\nround 1 accuracy: 0.3665\nEpoch [1/10]: Loss: 1.5155832290649414, Train accuracy: 0.45625, Test accuracy: 0.3474\nEpoch [2/10]: Loss: 1.4686368346214294, Train accuracy: 0.5, Test accuracy: 0.3584\nEpoch [3/10]: Loss: 1.410109770298004, Train accuracy: 0.496875, Test accuracy: 0.3498\nEpoch [4/10]: Loss: 1.3865095853805542, Train accuracy: 0.4890625, Test accuracy: 0.3414\nEpoch [5/10]: Loss: 1.3457111954689025, Train accuracy: 0.5078125, Test accuracy: 0.3497\nEpoch [6/10]: Loss: 1.247261607646942, Train accuracy: 0.5671875, Test accuracy: 0.3579\nEpoch [7/10]: Loss: 1.1464280426502227, Train accuracy: 0.5765625, Test accuracy: 0.3542\nEpoch [8/10]: Loss: 1.1201066851615906, Train accuracy: 0.6046875, Test accuracy: 0.3495\nEpoch [9/10]: Loss: 1.0462803065776825, Train accuracy: 0.6328125, Test accuracy: 0.3461\nEpoch [10/10]: Loss: 0.9470355093479157, Train accuracy: 0.65625, Test accuracy: 0.366\nk=0: 0.366\nEpoch [1/10]: Loss: 1.5497375845909118, Train accuracy: 0.434375, Test accuracy: 0.3645\nEpoch [2/10]: Loss: 1.5056135535240174, Train accuracy: 0.44375, Test accuracy: 0.3733\nEpoch [3/10]: Loss: 1.4431122899055482, Train accuracy: 0.4703125, Test accuracy: 0.3596\nEpoch [4/10]: Loss: 1.3782796263694763, Train accuracy: 0.484375, Test accuracy: 0.3576\nEpoch [5/10]: Loss: 1.3294195413589478, Train accuracy: 0.515625, Test accuracy: 0.3728\nEpoch [6/10]: Loss: 1.2975485563278197, Train accuracy: 0.5125, Test accuracy: 0.3762\nEpoch [7/10]: Loss: 1.2239425539970399, Train accuracy: 0.559375, Test accuracy: 0.3675\nEpoch [8/10]: Loss: 1.1421330928802491, Train accuracy: 0.58125, Test accuracy: 0.3766\nEpoch [9/10]: Loss: 1.0455137610435485, Train accuracy: 0.63125, Test accuracy: 0.3745\nEpoch [10/10]: Loss: 0.9817562937736511, Train accuracy: 0.659375, Test accuracy: 0.3745\nk=1: 0.3745\nround 2 accuracy: 0.3996\nEpoch [1/10]: Loss: 1.1862813234329224, Train accuracy: 0.5703125, Test accuracy: 0.3688\nEpoch [2/10]: Loss: 1.1167562842369079, Train accuracy: 0.6140625, Test accuracy: 0.3656\nEpoch [3/10]: Loss: 1.0541091859340668, Train accuracy: 0.6421875, Test accuracy: 0.3677\nEpoch [4/10]: Loss: 0.9112714886665344, Train accuracy: 0.690625, Test accuracy: 0.3883\nEpoch [5/10]: Loss: 0.7727681457996368, Train accuracy: 0.753125, Test accuracy: 0.3775\nEpoch [6/10]: Loss: 0.7137520015239716, Train accuracy: 0.753125, Test accuracy: 0.3644\nEpoch [7/10]: Loss: 0.635125133395195, Train accuracy: 0.815625, Test accuracy: 0.3709\nEpoch [8/10]: Loss: 0.5392308354377746, Train accuracy: 0.8203125, Test accuracy: 0.3765\nEpoch [9/10]: Loss: 0.4898455411195755, Train accuracy: 0.8359375, Test accuracy: 0.3706\nEpoch [10/10]: Loss: 0.491692915558815, Train accuracy: 0.84375, Test accuracy: 0.3751\nk=0: 0.3751\nEpoch [1/10]: Loss: 1.213739311695099, Train accuracy: 0.5546875, Test accuracy: 0.3849\nEpoch [2/10]: Loss: 1.138093602657318, Train accuracy: 0.578125, Test accuracy: 0.3942\nEpoch [3/10]: Loss: 1.0231439769268036, Train accuracy: 0.61875, Test accuracy: 0.3901\nEpoch [4/10]: Loss: 0.908240020275116, Train accuracy: 0.6828125, Test accuracy: 0.3853\nEpoch [5/10]: Loss: 0.8243722915649414, Train accuracy: 0.740625, Test accuracy: 0.381\nEpoch [6/10]: Loss: 0.7407168090343476, Train accuracy: 0.7453125, Test accuracy: 0.3933\nEpoch [7/10]: Loss: 0.6642298102378845, Train accuracy: 0.778125, Test accuracy: 0.376\nEpoch [8/10]: Loss: 0.626573970913887, Train accuracy: 0.7890625, Test accuracy: 0.3817\nEpoch [9/10]: Loss: 0.538983377814293, Train accuracy: 0.815625, Test accuracy: 0.3725\nEpoch [10/10]: Loss: 0.5512225389480591, Train accuracy: 0.815625, Test accuracy: 0.3644\nk=1: 0.3644\nround 3 accuracy: 0.404\nEpoch [1/10]: Loss: 0.9039218664169312, Train accuracy: 0.675, Test accuracy: 0.3682\nEpoch [2/10]: Loss: 0.9006373167037964, Train accuracy: 0.7, Test accuracy: 0.3715\nEpoch [3/10]: Loss: 0.6678150773048401, Train accuracy: 0.7671875, Test accuracy: 0.379\nEpoch [4/10]: Loss: 0.472028985619545, Train accuracy: 0.8546875, Test accuracy: 0.3783\nEpoch [5/10]: Loss: 0.369481286406517, Train accuracy: 0.8890625, Test accuracy: 0.3766\nEpoch [6/10]: Loss: 0.3229441612958908, Train accuracy: 0.909375, Test accuracy: 0.3769\nEpoch [7/10]: Loss: 0.3466216251254082, Train accuracy: 0.878125, Test accuracy: 0.3647\nEpoch [8/10]: Loss: 0.33928015232086184, Train accuracy: 0.875, Test accuracy: 0.3611\nEpoch [9/10]: Loss: 0.2860203832387924, Train accuracy: 0.903125, Test accuracy: 0.3691\nEpoch [10/10]: Loss: 0.19176748394966125, Train accuracy: 0.9453125, Test accuracy: 0.3752\nk=0: 0.3752\nEpoch [1/10]: Loss: 0.8659244120121002, Train accuracy: 0.671875, Test accuracy: 0.3862\nEpoch [2/10]: Loss: 0.7113367974758148, Train accuracy: 0.7421875, Test accuracy: 0.3797\nEpoch [3/10]: Loss: 0.5658994019031525, Train accuracy: 0.815625, Test accuracy: 0.3877\nEpoch [4/10]: Loss: 0.4710280030965805, Train accuracy: 0.8546875, Test accuracy: 0.3926\nEpoch [5/10]: Loss: 0.3938197284936905, Train accuracy: 0.8859375, Test accuracy: 0.3771\nEpoch [6/10]: Loss: 0.3220928221940994, Train accuracy: 0.915625, Test accuracy: 0.3935\nEpoch [7/10]: Loss: 0.24930471628904344, Train accuracy: 0.9375, Test accuracy: 0.3898\nEpoch [8/10]: Loss: 0.2154982417821884, Train accuracy: 0.9484375, Test accuracy: 0.3885\nEpoch [9/10]: Loss: 0.15742873549461364, Train accuracy: 0.965625, Test accuracy: 0.3853\nEpoch [10/10]: Loss: 0.11479622982442379, Train accuracy: 0.984375, Test accuracy: 0.3871\nk=1: 0.3871\nround 4 accuracy: 0.4101\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}